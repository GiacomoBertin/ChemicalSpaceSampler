{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b67c86",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f221ade0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.mu = nn.Linear(32, 32)\n",
    "        self.logstd = nn.Linear(32, 32)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        # x.shape Bx1024\n",
    "        h = self.encoder(x)\n",
    "        return self.mu(h), self.logstd(h)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = 1e-2 * torch.randn_like(std)\n",
    "           \n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "        \n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b729faf5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fingerprint_mols(mols, numBits = 1024):\n",
    "    \"\"\"Generates a morgan fingerprint for a list of smiles string.\n",
    "    :param mols: A smiles string for a molecule.\n",
    "    :param 2: The radius of the fingerprint.\n",
    "    :param num_bits: The number of bits to use in the fingerprint.\n",
    "    :return: A 1-D numpy array containing the morgan fingerprint.\n",
    "    \"\"\"\n",
    "    fps = []\n",
    "    for mol in mols:\n",
    "        mol = Chem.MolFromSmiles(mol)\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=numBits)\n",
    "        fp_arr = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(fp, fp_arr)\n",
    "        fps.append(fp_arr)\n",
    "    return fps \n",
    "\n",
    "\n",
    "def load_dataset(file_dg, file_smiles):\n",
    "    dataset = {}\n",
    "    with open(file_dg) as f_dg:\n",
    "        for line in f_dg:\n",
    "            w = line.split()\n",
    "            name = w[0][w[0].index('_') + 1:].replace('_', ' ')\n",
    "            dg = float(w[1])\n",
    "            dataset[name] = {'dg': dg, 'smiles': None}\n",
    "\n",
    "    smiles = []\n",
    "    dg = []\n",
    "    with open(file_smiles) as f_smiles:\n",
    "        for line in f_smiles:\n",
    "            w = line.split('\\t')\n",
    "            if len(w) == 3 and w[0] in dataset.keys():\n",
    "                name = w[0]\n",
    "                dataset[name]['smiles'] = w[-1].replace('\\n', '')\n",
    "                smiles.append(dataset[name]['smiles'])\n",
    "                dg.append(dataset[name]['dg'])\n",
    "\n",
    "    return dataset, smiles, dg\n",
    "\n",
    "dataset, smiles, dg = load_dataset('./DatabaseOMSDrugs_scores.dat', './DatabaseOMSDrugs.dat')\n",
    "\n",
    "\n",
    "class fpDataset(Dataset):\n",
    "    def __init__(self, chemical_space: List[np.array]):\n",
    "        self.chemical_space = chemical_space\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return torch.from_numpy(self.chemical_space[index]).float()\n",
    "    def __len__(self):\n",
    "        #len(dataset)\n",
    "        return len(self.chemical_space)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9566bd8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :1 \t loss: 9.5187\n",
      "epoch :2 \t loss: 2.8318\n",
      "epoch :3 \t loss: 0.7079\n",
      "epoch :4 \t loss: 0.2372\n",
      "epoch :5 \t loss: 0.0918\n",
      "epoch :6 \t loss: 0.0394\n",
      "epoch :7 \t loss: 0.0176\n",
      "epoch :8 \t loss: 0.0078\n",
      "epoch :9 \t loss: 0.0033\n",
      "epoch :10 \t loss: 0.0013\n",
      "epoch :11 \t loss: 0.0005\n",
      "epoch :12 \t loss: 0.0002\n",
      "epoch :13 \t loss: 0.0000\n",
      "epoch :14 \t loss: 0.0000\n",
      "epoch :15 \t loss: 0.0000\n",
      "epoch :16 \t loss: 0.0000\n",
      "epoch :17 \t loss: -0.0000\n",
      "epoch :18 \t loss: -0.0000\n",
      "epoch :19 \t loss: 0.0000\n",
      "epoch :20 \t loss: -0.0000\n",
      "epoch :21 \t loss: 0.0000\n",
      "epoch :22 \t loss: -0.0000\n",
      "epoch :23 \t loss: 0.0000\n",
      "epoch :24 \t loss: -0.0000\n",
      "epoch :25 \t loss: 0.0000\n",
      "epoch :26 \t loss: -0.0000\n",
      "epoch :27 \t loss: -0.0000\n",
      "epoch :28 \t loss: -0.0000\n",
      "epoch :29 \t loss: -0.0000\n",
      "epoch :30 \t loss: -0.0000\n",
      "epoch :31 \t loss: -0.0000\n",
      "epoch :32 \t loss: -0.0000\n",
      "epoch :33 \t loss: 0.0000\n",
      "epoch :34 \t loss: -0.0000\n",
      "epoch :35 \t loss: -0.0000\n",
      "epoch :36 \t loss: -0.0000\n",
      "epoch :37 \t loss: -0.0000\n",
      "epoch :38 \t loss: 0.0000\n",
      "epoch :39 \t loss: -0.0000\n",
      "epoch :40 \t loss: -0.0000\n",
      "epoch :41 \t loss: 0.0000\n",
      "epoch :42 \t loss: -0.0000\n",
      "epoch :43 \t loss: -0.0000\n",
      "epoch :44 \t loss: 0.0000\n",
      "epoch :45 \t loss: 0.0000\n",
      "epoch :46 \t loss: -0.0000\n",
      "epoch :47 \t loss: 0.0000\n",
      "epoch :48 \t loss: 0.0000\n",
      "epoch :49 \t loss: 0.0000\n",
      "epoch :50 \t loss: 0.0000\n",
      "epoch :51 \t loss: 0.0000\n",
      "epoch :52 \t loss: -0.0000\n",
      "epoch :53 \t loss: 0.0000\n",
      "epoch :54 \t loss: -0.0000\n",
      "epoch :55 \t loss: -0.0000\n",
      "epoch :56 \t loss: -0.0000\n",
      "epoch :57 \t loss: -0.0000\n",
      "epoch :58 \t loss: 0.0000\n",
      "epoch :59 \t loss: 0.0000\n",
      "epoch :60 \t loss: -0.0000\n",
      "epoch :61 \t loss: 0.0000\n",
      "epoch :62 \t loss: -0.0000\n",
      "epoch :63 \t loss: -0.0000\n",
      "epoch :64 \t loss: 0.0000\n",
      "epoch :65 \t loss: 0.0000\n",
      "epoch :66 \t loss: 0.0000\n",
      "epoch :67 \t loss: 0.0000\n",
      "epoch :68 \t loss: 0.0000\n",
      "epoch :69 \t loss: 0.0000\n",
      "epoch :70 \t loss: 0.0000\n",
      "epoch :71 \t loss: 0.0000\n",
      "epoch :72 \t loss: -0.0000\n",
      "epoch :73 \t loss: 0.0000\n",
      "epoch :74 \t loss: 0.0000\n",
      "epoch :75 \t loss: -0.0000\n",
      "epoch :76 \t loss: -0.0000\n",
      "epoch :77 \t loss: 0.0000\n",
      "epoch :78 \t loss: 0.0000\n",
      "epoch :79 \t loss: 0.0000\n",
      "epoch :80 \t loss: -0.0000\n",
      "epoch :81 \t loss: 0.0000\n",
      "epoch :82 \t loss: 0.0000\n",
      "epoch :83 \t loss: -0.0000\n",
      "epoch :84 \t loss: 0.0000\n",
      "epoch :85 \t loss: 0.0000\n",
      "epoch :86 \t loss: -0.0000\n",
      "epoch :87 \t loss: 0.0000\n",
      "epoch :88 \t loss: 0.0000\n",
      "epoch :89 \t loss: 0.0000\n",
      "epoch :90 \t loss: 0.0000\n",
      "epoch :91 \t loss: -0.0000\n",
      "epoch :92 \t loss: 0.0000\n",
      "epoch :93 \t loss: 0.0000\n",
      "epoch :94 \t loss: -0.0000\n",
      "epoch :95 \t loss: 0.0000\n",
      "epoch :96 \t loss: 0.0000\n",
      "epoch :97 \t loss: 0.0000\n",
      "epoch :98 \t loss: -0.0000\n",
      "epoch :99 \t loss: -0.0000\n",
      "epoch :100 \t loss: -0.0000\n"
     ]
    }
   ],
   "source": [
    "#supervisor.run_sampling_test(n_iterations=20, smiles=smiles, dg=dg)\n",
    "#defining the hyperparameters\n",
    "    \n",
    "\n",
    "epochs = 100\n",
    "vae = VAE()\n",
    "lr = 1e-2\n",
    "\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr)\n",
    "k = fingerprint_mols(smiles)\n",
    "dataset = fpDataset(k)\n",
    "train_loader = DataLoader(dataset = dataset, batch_size = 32,\n",
    "                       shuffle = True)\n",
    "\n",
    "# defining the loss function \n",
    "def loss_function(ỹ, y, mu, logvar):\n",
    "    BCE = nn.functional.binary_cross_entropy(ỹ, y)\n",
    "    #KLD = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD \n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = 0\n",
    "    #losses = []\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        #print(vae(batch)[0].shape)\n",
    "        data = vae(batch)[0]\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = vae(data)\n",
    "\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss\n",
    "        optimizer.step()\n",
    "        #losses.append(loss.detach().item())\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'epoch :{epoch} \\t loss: {loss:.4f}')\n",
    "        \n",
    "#supervisor.run_sampling_test(n_iterations=20, smiles=smiles, dg=dg)\n",
    "#defining the hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9105d19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}